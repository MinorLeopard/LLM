{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preparing Dataset for Tata Motors \n",
    "\n",
    "Equity instrument name: NSE_EQ|INE155A01022\n",
    "\n",
    "Futures instrument name:\n",
    "June: NSE_FO|63871\n",
    "July: NSE_FO|63853\n",
    "August: NSE_FO|56532\n",
    "\n",
    "Options Contract Instrument Name:\n",
    "TATAMOTORS24JUN960CE : NSE_FO|124632\n",
    "TATAMOTORS24JUN960PE : NSE_FO|124633\n",
    "TATAMOTORS24JUN1000CE : NSE_FO|124641\n",
    "TATAMOTORS24JUN1000PE : NSE_FO|124642\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upper Break and Buy Signal:\n",
    "\n",
    "Checks if there was an overlap between the Upper Break and Buy Signal.\n",
    "Lower Break and Sell Signal:\n",
    "\n",
    "Checks if there was an overlap between the Lower Break and Sell Signal.\n",
    "Upper BB values with Buy and Sell Signals:\n",
    "\n",
    "Checks if there was an overlap between Upper BB and Buy Signal, and Upper BB and Sell Signal.\n",
    "Lower BB values with Buy and Sell Signals:\n",
    "\n",
    "Checks if there was an overlap between Lower BB and Buy Signal, and Lower BB and Sell Signal.\n",
    "RSI values with Buy and Sell Signals:\n",
    "\n",
    "Checks if there was an overlap between RSI values and Buy Signal, and RSI values and Sell Signal.\n",
    "OBV values with Buy and Sell Signals:\n",
    "\n",
    "Checks if there was an overlap between OBV values and Buy Signal, and OBV values and Sell Signal.\n",
    "MACD values with Buy and Sell Signals:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 1139040 instruction-input-output triplets.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Load datasets\n",
    "ohlcv_data = pd.read_csv('../Charting System/IndicatorData/NSE_EQ_INE155A01022/ohlcv_data_NSE_EQ_INE155A01022_2024-06-14.csv')\n",
    "hardy_indicator_data = pd.read_csv('../Charting System/IndicatorData/NSE_EQ_INE155A01022/hardy_indicator_data_NSE_EQ_INE155A01022_2024-06-14.csv')\n",
    "obv_data = pd.read_csv('../Charting System/IndicatorData/NSE_EQ_INE155A01022/obv_data_NSE_EQ_INE155A01022_2024-06-14.csv')\n",
    "rsi_histo_alert_data = pd.read_csv('../Charting System/IndicatorData/NSE_EQ_INE155A01022/rsiHistoAlert_data_NSE_EQ_INE155A01022_2024-06-14.csv')\n",
    "trendlines_data = pd.read_csv('../Charting System/IndicatorData/NSE_EQ_INE155A01022/trendlines_data_NSE_EQ_INE155A01022_2024-06-14.csv')\n",
    "volume_spike_data = pd.read_csv('../Charting System/IndicatorData/NSE_EQ_INE155A01022/volume_spike_data_NSE_EQ_INE155A01022_2024-06-14.csv')\n",
    "\n",
    "# Merge datasets on common keys (e.g., 'Date')\n",
    "merged_data = ohlcv_data.merge(hardy_indicator_data, on=['Date'], how='left', suffixes=('', '_hardy'))\n",
    "merged_data = merged_data.merge(obv_data, on=['Date'], how='left', suffixes=('', '_obv'))\n",
    "merged_data = merged_data.merge(rsi_histo_alert_data, on=['Date'], how='left', suffixes=('', '_rsi'))\n",
    "merged_data = merged_data.merge(trendlines_data, on=['Date'], how='left', suffixes=('', '_trendlines'))\n",
    "merged_data = merged_data.merge(volume_spike_data, on=['Date'], how='left', suffixes=('', '_volumespike'))\n",
    "\n",
    "# Function to generate instruction-input-output triplets\n",
    "def generate_qa_pairs(row):\n",
    "    pairs = []\n",
    "\n",
    "    # OHLCV Data\n",
    "    instruction = \"Provide the OHLCV data for the given date.\"\n",
    "    input_text = f\"Date: {row['Date']}\"\n",
    "    output_text = f\"Open: {row['Open']}, High: {row['High']}, Low: {row['Low']}, Close: {row['Close']}, Volume: {row['Volume']}\"\n",
    "    pairs.append({\"instruction\": instruction, \"input\": input_text, \"output\": output_text})\n",
    "\n",
    "    # RSI Histo Alert Data\n",
    "    instruction = \"Provide the RSI Histo Alert data for the given date.\"\n",
    "    input_text = f\"Date: {row['Date']}\"\n",
    "    color = 'Positive' if row['Color'] == 'Green' else 'Neutral' if row['Color'] == 'Blue' else 'Negative'\n",
    "    output_text = f\"RSI: {row['RSI_Histo']}, Candle: {color}\"\n",
    "    pairs.append({\"instruction\": instruction, \"input\": input_text, \"output\": output_text})\n",
    "\n",
    "    # Volume Spike Data\n",
    "    instruction = \"Provide the Volume Spike data for the given date.\"\n",
    "    input_text = f\"Date: {row['Date']}\"\n",
    "    output_text = f\"HA_High: {row['HA_High']}, HA_Low: {row['HA_Low']}, Volume_Flow: {row['Volume_Flow']}, Volume_Spike: {row['Volume_Spike']}\"\n",
    "    pairs.append({\"instruction\": instruction, \"input\": input_text, \"output\": output_text})\n",
    "\n",
    "    # Trendlines Data\n",
    "    instruction = \"Provide the Trendlines data for the given date.\"\n",
    "    input_text = f\"Date: {row['Date']}\"\n",
    "    output_text = f\"Upper_Trendline: {row.get('Upper_Trendline', 'N/A')}, Lower_Trendline: {row.get('Lower_Trendline', 'N/A')}, Upper_Break: {row.get('Upper_Break', 'N/A')}, Lower_Break: {row.get('Lower_Break', 'N/A')}\"\n",
    "    pairs.append({\"instruction\": instruction, \"input\": input_text, \"output\": output_text})\n",
    "\n",
    "    # OBV Data\n",
    "    instruction = \"Provide the OBV data for the given date.\"\n",
    "    input_text = f\"Date: {row['Date']}\"\n",
    "    output_text = f\"OBV: {row['OBV']}, OBV_Fast_EMA: {row.get('OBV_Fast_EMA', 'N/A')}, OBV_Medium_EMA: {row.get('OBV_Medium_EMA', 'N/A')}, OBV_Slow_EMA: {row.get('OBV_Slow_EMA', 'N/A')}, Donchian_Baseline: {row.get('Donchian_Baseline', 'N/A')}\"\n",
    "    pairs.append({\"instruction\": instruction, \"input\": input_text, \"output\": output_text})\n",
    "\n",
    "    # Hardy Indicator Data\n",
    "    instruction = \"Provide the Hardy Indicator data for the given date.\"\n",
    "    input_text = f\"Date: {row['Date']}\"\n",
    "    output_text = (f\"MiddleBB: {row['MiddleBB']}, StdDev: {row['StdDev']}, UpperBB: {row['UpperBB']}, LowerBB: {row['LowerBB']}, EMA_Fast: {row['EMA_Fast']}, EMA_Slow: {row['EMA_Slow']}, MACD: {row['MACD']}, Signal_Line: {row['Signal_Line']}, \"\n",
    "                   f\"BuySignal: {row['BuySignal']}, SellSignal: {row['SellSignal']}, MACD_Angle: {row['MACD_Angle']}, Crossed_LowerBB: {row['Crossed_LowerBB']}, MACD_Angle_Less_than_5: {row['MACD_Angle_Less_Than_5']}, \"\n",
    "                   f\"Final_Buy_Signal: {row['Buy_Signal']}, Crossed_UpperBB: {row['Crossed_UpperBB']}, MACD_Greater_than_Neg5: {row['MACD_Angle_Greater_Than_Neg5']}, Final_Short_Signal: {row['Short_Signal']}\")\n",
    "    pairs.append({\"instruction\": instruction, \"input\": input_text, \"output\": output_text})\n",
    "\n",
    "    # Overlap checks for each indicator combination\n",
    "    overlap_checks = [\n",
    "        (\"BuySignal\", \"SellSignal\"),\n",
    "        (\"MACD_Angle_Less_Than_5\", \"Crossed_LowerBB\"),\n",
    "        (\"MACD_Angle_Greater_Than_Neg5\", \"Crossed_UpperBB\"),\n",
    "        (\"Buy_Signal\", \"Short_Signal\"),\n",
    "        (\"Upper_Break\", \"Buy_Signal\"),\n",
    "        (\"Lower_Break\", \"Short_Signal\"),\n",
    "        (\"UpperBB\", \"Buy_Signal\"),\n",
    "        (\"UpperBB\", \"Short_Signal\"),\n",
    "        (\"LowerBB\", \"BuySignal\"),\n",
    "        (\"LowerBB\", \"Short_Signal\"),\n",
    "        (\"RSI_Histo\", \"BuySignal\"),\n",
    "        (\"RSI_Histo\", \"Short_Signal\"),\n",
    "        (\"OBV\", \"BuySignal\"),\n",
    "        (\"OBV\", \"Short_Signal\"),\n",
    "        (\"MiddleBB\", \"BuySignal\"),\n",
    "        (\"MiddleBB\", \"Short_Signal\"),\n",
    "        (\"MACD\", \"BuySignal\"),\n",
    "        (\"MACD\", \"Short_Signal\"),\n",
    "        # Add more combinations as needed\n",
    "    ]\n",
    "\n",
    "    for indicator1, indicator2 in overlap_checks:\n",
    "        instruction = f\"Was there an overlap of {indicator1} and {indicator2} on the given date?\"\n",
    "        input_text = f\"Date: {row['Date']}\"\n",
    "        if row.get(indicator1) and row.get(indicator2):\n",
    "            output_text = f\"Yes, there was an overlap of {indicator1} and {indicator2} on {row['Date']}.\"\n",
    "        else:\n",
    "            output_text = f\"No, there was no overlap of {indicator1} and {indicator2} on {row['Date']}.\"\n",
    "        pairs.append({\"instruction\": instruction, \"input\": input_text, \"output\": output_text})\n",
    "\n",
    "    return pairs\n",
    "\n",
    "# Generate QA pairs for the entire dataset\n",
    "qa_dataset = []\n",
    "for _, row in merged_data.iterrows():\n",
    "    qa_dataset.extend(generate_qa_pairs(row))\n",
    "\n",
    "# Save the dataset to a JSONL file\n",
    "with open('qa_TATAMOTORS_dataset.jsonl', 'w') as f:\n",
    "    f.write('[\\n')\n",
    "    for i, entry in enumerate(qa_dataset):\n",
    "        json.dump(entry, f, indent=4)\n",
    "        if i < len(qa_dataset) - 1:\n",
    "            f.write(',\\n')\n",
    "    f.write('\\n]')\n",
    "\n",
    "print(f\"Generated {len(qa_dataset)} instruction-input-output triplets.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Completed Generation of Training Dataset from 2023-01-01 to 2024-06-15 for Equity TATA MOTORS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.1+cpu\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(torch.__version__)\n",
    "print(torch.cuda.is_available())  # This will tell you if CUDA (GPU support) is available\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Python\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CPU\n",
      "Loading tokenizer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizer loaded.\n",
      "Loading model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "import os\n",
    "\n",
    "# Define the path where the model is saved\n",
    "model_path = 'finetuned_llama3'  # Update this to the path where you saved the model\n",
    "\n",
    "# Check for GPU/CPU availability\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(f\"Using GPU: {torch.cuda.get_device_name(0)}\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"Using CPU\")\n",
    "\n",
    "# Limit the number of threads used by PyTorch\n",
    "torch.set_num_threads(4)\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"4\"\n",
    "\n",
    "try:\n",
    "    print(\"Loading tokenizer...\")\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "    print(\"Tokenizer loaded.\")\n",
    "\n",
    "    print(\"Loading model...\")\n",
    "    model = AutoModelForCausalLM.from_pretrained(model_path, low_cpu_mem_usage=True).to(device)\n",
    "    print(\"Model loaded.\")\n",
    "\n",
    "    # Example usage\n",
    "    input_text = \"What is the latest price of TATA Motors?\"\n",
    "    input_ids = tokenizer.encode(input_text, return_tensors='pt').to(device)\n",
    "\n",
    "    # Generate a response from the model\n",
    "    print(\"Generating response...\")\n",
    "    outputs = model.generate(input_ids, max_length=50, num_return_sequences=1)\n",
    "    print(\"Response generated.\")\n",
    "\n",
    "    generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    print(\"Decoded generated text.\")\n",
    "\n",
    "    print(f\"Generated text: {generated_text}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {str(e)}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
